量化学习1.3：下载及规整数据

在那没有免费数据接口的漫漫长夜，买不起数据的屌丝数据分析师非常痛苦；
异常痛苦的是，pandas包出现之前，matlab和R对于时间序列的处理，虽然支持，但不完善；
而且，在那一个策略能跑两个小时的年代，机器学习的人，该怎么活啊……

现在，数据接口至少有Tushare，再不济就从新浪等网站上爬；
pandas包，瑞士军刀；
cpu的主频不再是问题，何况还有12核的AMD；
AMD算什么，看N卡的GPU！

闲话就说这么多，进入正题。

要做量化，首先要有数据。数据有好有坏，质量差别挺大。仅复权一项，就很折腾，况且还有退市、暂停交易等等，数据清洗工作很重要，在其他行业的数据分析师里，特别是机器学习的人，会说 垃圾进 垃圾出。
收费的就不说了，免费才是大大众的需求。

目前A股数据做的比较好和有名的，主要有Tushare、vnpy、rqalpha、easytrader（只用过Tushare的，其他三家还没用过）。以前聚宽据说不收费，现在每月也收了，因此在起步阶段，用Tushare足够了。

TuShare -财经数据接口包  http://tushare.org/classifying.html
参看数据接口包，写循环命令，下载数据到本地。熟悉MySQL的可以下载到数据库，不熟悉的就保存成csv。

步骤1：下载指数数据列表

量化学习1.3：下载及规整数据

步骤2：根据列表下载数据

量化学习1.3：下载及规整数据

步骤3：根据需要规整数据

量化学习1.3：下载及规整数据

在数据规整结束后，才能够进入数据分析。

在下载时有不少要注意的地方，说一些，供参考。

1.复权。
复权才能够反映股票的真实变动，所以要下载复权数据。但是，一旦复权，之前的数据也都要改变。
所以，要么是爬配股和分红信息并按照公式对未复权数据计算，要么是重新下载数据。
还想到一种方法，把第n日前后数据比较，如果不一样就把当日信息找出来，然后对复权数据计算。算是第一种的改进，省的算那么多了。

2.get_k_date里的start_time设定。
如果设定开始日期在股票发行之前，那就会报错，写循环时就麻烦了。因此，要么就用try except 过去，要么就不设定开始时间。

3.每日更新list
目前新股发行很快，如果没有即时更新股票list，会造成较大误差。
